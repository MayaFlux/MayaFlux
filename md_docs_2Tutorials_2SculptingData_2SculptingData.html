<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>MayaFlux: MayaFlux Tutorial: Sculpting Data Part I</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">MayaFlux<span id="projectnumber">&#160;0.2.0</span>
   </div>
   <div id="projectbrief">Digital-First Multimedia Processing Framework</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('md_docs_2Tutorials_2SculptingData_2SculptingData.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">MayaFlux Tutorial: Sculpting Data Part I</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="autotoc_md456"></a> In <a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a>, data isn’t something you use -&gt; it’s something you shape. Sound, light, numbers, all share the same substrate. You don’t generate a waveform; you sculpt a pattern of information and let it move. These tutorials begin with the smallest gesture (loading a file) and expand until you can construct entire temporal architectures. The point is not playback. The point is agency over time.</p>
<p>Every example you run produces real sound, but the goal is not sound itself — the goal is to understand the movement of information.</p>
<p>The different "runnable" code in these tutorial are always after a heading called <code>Tutorial:</code> and after explainations, under the heading <code>Try it</code>:</p>
<p>If you simply want to run the code, look for <code>Turorial:</code> heading and then <code>Try it</code> sections.</p>
<p>Each section in this series introduces one idea:</p>
<ul>
<li>A way of structuring data</li>
<li>A way of scheduling time</li>
<li>A way of controlling how information flows</li>
</ul>
<p>Together, they form the foundation of digital composition — not in the musical sense, but in the computational one.</p>
<p>What you’ll do here:</p>
<ul>
<li>Load data and inspect its structure</li>
<li>Connect it to buffers and observe flow</li>
<li>Insert processors and shape transformations</li>
<li>Learn how timing and cycles define motion</li>
</ul>
<p>Eventually, build declarative pipelines that describe complete computational events</p>
<p>What you won’t do here:</p>
<ul>
<li>Build UIs or “patches”</li>
<li>Work through effects lists or presets</li>
<li>Simulate analog workflows</li>
</ul>
<p>Everything here is real code: The same logic that runs inside the <a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a> engine. You’ll read it, modify it, and run it directly.</p>
<p>Each step is designed to teach you how the system thinks, so that later, when you invent something new, you can do so fluently without waiting for someone else to provide the building blocks.</p>
<ul>
<li>Tutorial: Sculpting Data{#toc-tutorial-sculpting-data}<ul>
<li>The Simplest First Step{#toc-the-simplest-first-step}</li>
<li>Expansion 1: What Is a Container?{#toc-expansion-1-what-is-a-container}</li>
<li>Expansion 2: Memory, Ownership, and Smart Pointers{#toc-expansion-2-memory-ownership-and-smart-pointers}</li>
<li>Expansion 3: What is `vega`?{#toc-expansion-3-what-is-vega}</li>
<li>Expansion 4: The Container's Processor{#toc-expansion-4-the-containers-processor}</li>
<li>Expansion 5: What `.read_audio()` Does NOT Do{#toc-expansion-5-what-.read_audio-does-not-do}</li>
</ul>
</li>
<li>Tutorial: Connect to Buffers{#toc-tutorial-connect-to-buffers}<ul>
<li>The Next Step{#toc-the-next-step}</li>
<li>Expansion 1: What Are Buffers?{#toc-expansion-1-what-are-buffers}</li>
<li>Expansion 2: Why Per-Channel Buffers?{#toc-expansion-2-why-per-channel-buffers}</li>
<li>Expansion 3: The Buffer Manager and Buffer Lifecycle{#toc-expansion-3-the-buffer-manager-and-buffer-lifecycle}</li>
<li>Expansion 4: SoundContainerBuffer---The Bridge{#toc-expansion-4-containerbufferthe-bridge}</li>
<li>Expansion 5: Processing Token---AUDIO_BACKEND{#toc-expansion-5-processing-tokenaudio_backend}</li>
<li>Expansion 6: Accessing the Buffers{#toc-expansion-6-accessing-the-buffers}</li>
<li>The Fluent vs. Explicit Comparison{#toc-the-fluent-vs.-explicit-comparison}<ul>
<li>Fluent (What happens behind the scenes){#toc-fluent-what-happens-behind-the-scenes}</li>
<li>Explicit (What's actually happening){#toc-explicit-whats-actually-happening}</li>
</ul>
</li>
<li>Try It{#toc-try-it}</li>
</ul>
</li>
<li>Tutorial: Buffers Own Chains{#toc-tutorial-buffers-own-chains}<ul>
<li>The Simplest Path{#toc-the-simplest-path}</li>
<li>Expansion 1: What Is `vega.IIR()`?{#toc-expansion-1-what-is-vega.iir}</li>
<li>Expansion 2: What Is `MayaFlux::create_processor()`?{#toc-expansion-2-what-is-mayafluxcreate_processor}</li>
<li>Expansion 3: What Is a Processing Chain?{#toc-expansion-3-what-is-a-processing-chain}</li>
<li>Expansion 4: Adding Processor to Another Channel (Optional){#toc-expansion-4-adding-processor-to-another-channel-optional}</li>
<li>Expansion 5: What Happens Inside{#toc-expansion-5-what-happens-inside}</li>
<li>Expansion 6: Processors Are Reusable Building Blocks{#toc-expansion-6-processors-are-reusable-building-blocks}</li>
<li>Try It{#toc-try-it-1}</li>
</ul>
</li>
<li>Tutorial: Timing, Streams, and Bridges{#toc-tutorial-timing-streams-and-bridges}<ul>
<li>The Current Continous Flow{#toc-the-current-continous-flow}</li>
<li>Where We're Going{#toc-where-were-going}</li>
<li>Expansion 1: The Architecture of Containers{#toc-expansion-1-the-architecture-of-containers}</li>
<li>Expansion 2: Enter DynamicSoundStream{#toc-expansion-2-enter-dynamicsoundstream}</li>
<li>Expansion 3: SoundStreamWriter{#toc-expansion-3-streamwriteprocessor}</li>
<li>Expansion 4: SoundFileBridge---Controlled Flow{#toc-expansion-4-filebridgebuffercontrolled-flow}</li>
<li>Expansion 5: Why This Architecture?{#toc-expansion-5-why-this-architecture}</li>
<li>Expansion 6: From File to Cycle{#toc-expansion-6-from-file-to-cycle}</li>
<li>The Three Key Concepts{#toc-the-three-key-concepts}</li>
<li>Why This Section Has No Audio Code{#toc-why-this-section-has-no-audio-code}</li>
<li>What You Should Internalize{#toc-what-you-should-internalize}</li>
</ul>
</li>
<li>Tutorial: Buffer Pipelines (Teaser){#toc-tutorial-buffer-pipelines-teaser}<ul>
<li>The Next Level{#toc-the-next-level}</li>
<li>A Taste{#toc-a-taste}</li>
<li>Expansion 1: What Is a Pipeline?{#toc-expansion-1-what-is-a-pipeline}</li>
<li>Expansion 2: BufferOperation Types{#toc-expansion-2-bufferoperation-types}</li>
<li>Expansion 3: The `on_capture_processing` Pattern{#toc-expansion-3-the-on_capture_processing-pattern}</li>
<li>Expansion 4: Why This Matters{#toc-expansion-4-why-this-matters}</li>
<li>What Happens Next{#toc-what-happens-next}</li>
<li>Try It (Optional){#toc-try-it-optional}</li>
<li>The Philosophy{#toc-the-philosophy}</li>
<li>Next: The Full Pipeline Tutorial{#toc-next-the-full-pipeline-tutorial}</li>
</ul>
</li>
</ul>
<h1><a class="anchor" id="autotoc_md457"></a>
Tutorial: The Simplest First Step</h1>
<p>Run this code. The file is loaded into memory.</p>
<div class="fragment"><div class="line"><span class="comment">// In your src/user_project.hpp compose() function:</span></div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">void</span> compose() {</div>
<div class="line">    <span class="keyword">auto</span> sound_container = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a8437a7d641c0011d359c38f13881adc0.html#a8437a7d641c0011d359c38f13881adc0">read_audio</a>(<span class="stringliteral">&quot;path/to/your/file.wav&quot;</span>);</div>
<div class="line">}</div>
<div class="ttc" id="aclassMayaFlux_1_1Creator_a8437a7d641c0011d359c38f13881adc0_html_a8437a7d641c0011d359c38f13881adc0"><div class="ttname"><a href="classMayaFlux_1_1Creator_a8437a7d641c0011d359c38f13881adc0.html#a8437a7d641c0011d359c38f13881adc0">MayaFlux::Creator::read_audio</a></div><div class="ttdeci">auto read_audio(const std::string &amp;filepath) -&gt; CreationHandle&lt; Kakshya::SoundFileContainer &gt;</div><div class="ttdef"><b>Definition</b> <a href="Creator_8hpp_source.html#l00213">Creator.hpp:213</a></div></div>
</div><!-- fragment --><p>Replace <code>"path/to/your/file.wav"</code> with an actual path to a <code>.wav</code> file.</p>
<p>Run the program. You'll see console output showing what loaded:</p>
<div class="fragment"><div class="line">✓ Loaded: path/to/your/file.wav</div>
<div class="line">  Channels: 2</div>
<div class="line">  Frames: 2304000</div>
<div class="line">  Sample Rate: 48000 Hz</div>
</div><!-- fragment --><p>Nothing plays yet. That's intentional—and important. The rest of this section shows you what just happened.</p>
<p>You have:</p>
<ul>
<li>All audio data in memory</li>
<li>Organized as a Container with metadata</li>
<li>A processor attached, ready to chunk and feed data</li>
<li>Full control over what happens next</li>
</ul>
<p>The file is loaded. Ready. Waiting.</p>
<h2><a class="anchor" id="autotoc_md458"></a>
Expansion 1: What Is a Container?</h2>
<details >
<summary >
Details</summary>
<p>&lt;parameter name="open"&gt;</p>
<p>When you call <code>vega.read_audio()</code>, you're not just reading bytes from disk and forgetting them. You're creating a **Container**—a structure that holds:</p>
<ul>
<li><b>The audio data itself</b> (all samples as numbers, deinterleaved and ready to process)</li>
<li><b>Metadata about the data</b> (sample rate, channels, duration, number of frames)</li>
<li><b>A processor</b> (machinery that knows how to access this data efficiently)</li>
<li><b>Organizational structure</b> (dimensions: time, channels, memory layout)</li>
</ul>
<p>The difference: A file is <b>inert</b>. A Container is <b>active creative material</b>. It knows its own shape. It can tell you about regions within itself. It can be queried, transformed, integrated with other Containers.</p>
<p>When <code>vega.read_audio("file.wav")</code> runs, <a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a>:</p>
<ol type="1">
<li>Creates a <code>SoundFileReader</code> and initializes FFmpeg</li>
<li>Checks if the file is readable</li>
<li>Resamples to your project's sample rate (configurable)</li>
<li>Converts to 64-bit depth (high precision)</li>
<li><b>Deinterleaves</b> the audio (separates channels into independent arrays—more efficient for processing)</li>
<li>Creates a <code>SoundFileContainer</code> object</li>
<li>Loads all the audio data into memory</li>
<li>Configures a <code><a class="el" href="classContiguousAccessProcessor.html" title="Data Processor for efficient, sequential access to N-dimensional data containers.">ContiguousAccessProcessor</a></code> (the Container's default processor, which knows how to feed data to buffers chunk-by-chunk)</li>
<li>Returns the Container to you</li>
</ol>
<p>The Container is now your interface to that audio data. It's ready to be routed, processed, analyzed, transformed.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md459"></a>
Expansion 2: Memory, Ownership, and Smart Pointers</h2>
<details >
<summary >
Details</summary>
<p>&lt;parameter name="open"&gt;</p>
<p>As you know, raw audio data can be large. <a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a> allocates and manages it safely through smart pointers.</p>
<p>At a lower, machine-level (in programming parlance), the user is expected to manage memory manually: instantiate objects, bind them, handle transfers, and delete when done. Any misalignment among these steps can cause crashes or undefined behavior. <a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a> doesn’t expect you to handle these manually—unless you choose to.</p>
<p><a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a> uses **smart pointers**—a C++11 feature that automatically tracks how many parts of your program are using a Container. When the last reference disappears, the memory is freed automatically.</p>
<p>When you write:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> sound_container = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a8437a7d641c0011d359c38f13881adc0.html#a8437a7d641c0011d359c38f13881adc0">read_audio</a>(<span class="stringliteral">&quot;file.wav&quot;</span>);</div>
</div><!-- fragment --><p>What's actually happening is:</p>
<div class="fragment"><div class="line">std::shared_ptr&lt;MayaFlux::Kakshya::SoundFileContainer&gt; sound_container =</div>
<div class="line">    <span class="comment">/* vega.read_audio() internally creates and returns a shared_ptr */</span>;</div>
</div><!-- fragment --><p>You don't see <code>std::shared_ptr</code>. You see <code>auto</code>. But <a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a> is using it. This means:</p>
<ul>
<li><b>You never manually <code>delete</code> the Container.</b> It handles itself.</li>
<li><b>Multiple parts of your code can reference the same Container</b> without worrying about who's responsible for cleanup.</li>
<li><b>When the last reference is gone</b>, memory is automatically released.</li>
</ul>
<p>This is why <code>vega.read_audio()</code> is safe. The complexity of memory management exists—it's just not your problem.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md460"></a>
Expansion 3: What is &lt;tt&gt;vega&lt;/tt&gt;?</h2>
<details >
<summary >
Details</summary>
<p>&lt;parameter name="open"&gt;</p>
<p><code>vega</code> is a **fluent interface**—a convenience layer that takes <a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a>'s power and hides the verbosity without hiding the machinery. Grappling with complexity generally yields expressive, and often well-reasoned, implementations. However, many find it hard to parse the wall of code that results from such grappling, partly because machine-level languages tend to prioritize other aspects of coding over user experience (UX).</p>
<p>Making complex logic less verbose can be a good way to encourage more people to explore.</p>
<p>If you didn't have <code>vega</code>, loading a file would look like this:</p>
<div class="fragment"><div class="line"><span class="comment">// Without vega - explicit, showing every step</span></div>
<div class="line"><span class="keyword">auto</span> reader = std::make_unique&lt;MayaFlux::IO::SoundFileReader&gt;();</div>
<div class="line"><a class="code hl_function" href="classMayaFlux_1_1IO_1_1SoundFileReader_af5ff225c8236374ba20a58bd13e0bb45.html#af5ff225c8236374ba20a58bd13e0bb45">MayaFlux::IO::SoundFileReader::initialize_ffmpeg</a>();</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span> (!reader-&gt;can_read(<span class="stringliteral">&quot;file.wav&quot;</span>)) {</div>
<div class="line">    std::cerr &lt;&lt; <span class="stringliteral">&quot;Cannot read file\n&quot;</span>;</div>
<div class="line">    <span class="keywordflow">return</span>;</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">reader-&gt;set_target_sample_rate(<a class="code hl_function" href="namespaceMayaFlux_1_1Config_ad8c6968db02415b5ba48863063076989.html#ad8c6968db02415b5ba48863063076989">MayaFlux::Config::get_sample_rate</a>());</div>
<div class="line">reader-&gt;set_target_bit_depth(64);</div>
<div class="line">reader-&gt;set_audio_options(<a class="code hl_enumvalue" href="namespaceMayaFlux_1_1IO_a57129e4c6aa0f25e478f7bbc53b03aa7.html#a57129e4c6aa0f25e478f7bbc53b03aa7a63a53ce4a5b43a6029c80bae335dbd54">MayaFlux::IO::AudioReadOptions::DEINTERLEAVE</a>);</div>
<div class="line"> </div>
<div class="line"><a class="code hl_enumeration" href="namespaceMayaFlux_1_1IO_a582f5249ec35cc284ce9e293ef33d9ce.html#a582f5249ec35cc284ce9e293ef33d9ce">MayaFlux::IO::FileReadOptions</a> options = <a class="code hl_enumvalue" href="namespaceMayaFlux_1_1IO_a582f5249ec35cc284ce9e293ef33d9ce.html#a582f5249ec35cc284ce9e293ef33d9cea2e5626de6a522fd3e19b15f26dd26293">MayaFlux::IO::FileReadOptions::EXTRACT_METADATA</a>;</div>
<div class="line"><span class="keywordflow">if</span> (!reader-&gt;open(<span class="stringliteral">&quot;file.wav&quot;</span>, options)) {</div>
<div class="line">        <a class="code hl_define" href="Archivist_8hpp_a53988b7d19f23b49124b779f412e32bb.html#a53988b7d19f23b49124b779f412e32bb">MF_ERROR</a>(Journal::Component::API, Journal::Context::FileIO, <span class="stringliteral">&quot;Failed to open file: {}&quot;</span>, reader-&gt;get_last_error());</div>
<div class="line">    <span class="keywordflow">return</span>;</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="keyword">auto</span> container = reader-&gt;create_container();</div>
<div class="line"><span class="keyword">auto</span> sound_container = std::dynamic_pointer_cast&lt;Kakshya::SoundFileContainer&gt;(container);</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span> (!reader-&gt;load_into_container(sound_container)) {</div>
<div class="line">        <a class="code hl_define" href="Archivist_8hpp_a53988b7d19f23b49124b779f412e32bb.html#a53988b7d19f23b49124b779f412e32bb">MF_ERROR</a>(Journal::Component::API, Journal::Context::Runtime, <span class="stringliteral">&quot;Failed to load audio data: {}&quot;</span>, reader-&gt;get_last_error());</div>
<div class="line">    <span class="keywordflow">return</span>;</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="keyword">auto</span> processor = std::dynamic_pointer_cast&lt;Kakshya::ContiguousAccessProcessor&gt;(</div>
<div class="line">    sound_container-&gt;get_default_processor());</div>
<div class="line"><span class="keywordflow">if</span> (processor) {</div>
<div class="line">    std::vector&lt;uint64_t&gt; output_shape = {</div>
<div class="line">        <a class="code hl_function" href="namespaceMayaFlux_1_1Config_a5249afad2e4d9b92e843da6b0d089926.html#a5249afad2e4d9b92e843da6b0d089926">MayaFlux::Config::get_buffer_size</a>(),</div>
<div class="line">        sound_container-&gt;get_num_channels()</div>
<div class="line">    };</div>
<div class="line">    processor-&gt;set_output_size(output_shape);</div>
<div class="line">    processor-&gt;set_auto_advance(<span class="keyword">true</span>);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Now you have sound_container</span></div>
<div class="ttc" id="aArchivist_8hpp_a53988b7d19f23b49124b779f412e32bb_html_a53988b7d19f23b49124b779f412e32bb"><div class="ttname"><a href="Archivist_8hpp_a53988b7d19f23b49124b779f412e32bb.html#a53988b7d19f23b49124b779f412e32bb">MF_ERROR</a></div><div class="ttdeci">#define MF_ERROR(comp, ctx,...)</div><div class="ttdef"><b>Definition</b> <a href="Archivist_8hpp_source.html#l00382">Archivist.hpp:382</a></div></div>
<div class="ttc" id="aclassMayaFlux_1_1IO_1_1SoundFileReader_af5ff225c8236374ba20a58bd13e0bb45_html_af5ff225c8236374ba20a58bd13e0bb45"><div class="ttname"><a href="classMayaFlux_1_1IO_1_1SoundFileReader_af5ff225c8236374ba20a58bd13e0bb45.html#af5ff225c8236374ba20a58bd13e0bb45">MayaFlux::IO::SoundFileReader::initialize_ffmpeg</a></div><div class="ttdeci">static void initialize_ffmpeg()</div><div class="ttdoc">Initialize FFmpeg libraries (thread-safe, called automatically).</div><div class="ttdef"><b>Definition</b> <a href="SoundFileReader_8cpp_source.html#l00099">SoundFileReader.cpp:99</a></div></div>
<div class="ttc" id="anamespaceMayaFlux_1_1Config_a5249afad2e4d9b92e843da6b0d089926_html_a5249afad2e4d9b92e843da6b0d089926"><div class="ttname"><a href="namespaceMayaFlux_1_1Config_a5249afad2e4d9b92e843da6b0d089926.html#a5249afad2e4d9b92e843da6b0d089926">MayaFlux::Config::get_buffer_size</a></div><div class="ttdeci">uint32_t get_buffer_size()</div><div class="ttdoc">Gets the buffer size from the default engine.</div><div class="ttdef"><b>Definition</b> <a href="Config_8cpp_source.html#l00054">Config.cpp:54</a></div></div>
<div class="ttc" id="anamespaceMayaFlux_1_1Config_ad8c6968db02415b5ba48863063076989_html_ad8c6968db02415b5ba48863063076989"><div class="ttname"><a href="namespaceMayaFlux_1_1Config_ad8c6968db02415b5ba48863063076989.html#ad8c6968db02415b5ba48863063076989">MayaFlux::Config::get_sample_rate</a></div><div class="ttdeci">uint32_t get_sample_rate()</div><div class="ttdoc">Gets the sample rate from the default engine.</div><div class="ttdef"><b>Definition</b> <a href="Config_8cpp_source.html#l00045">Config.cpp:45</a></div></div>
<div class="ttc" id="anamespaceMayaFlux_1_1IO_a57129e4c6aa0f25e478f7bbc53b03aa7_html_a57129e4c6aa0f25e478f7bbc53b03aa7a63a53ce4a5b43a6029c80bae335dbd54"><div class="ttname"><a href="namespaceMayaFlux_1_1IO_a57129e4c6aa0f25e478f7bbc53b03aa7.html#a57129e4c6aa0f25e478f7bbc53b03aa7a63a53ce4a5b43a6029c80bae335dbd54">MayaFlux::IO::AudioReadOptions::DEINTERLEAVE</a></div><div class="ttdeci">@ DEINTERLEAVE</div></div>
<div class="ttc" id="anamespaceMayaFlux_1_1IO_a582f5249ec35cc284ce9e293ef33d9ce_html_a582f5249ec35cc284ce9e293ef33d9ce"><div class="ttname"><a href="namespaceMayaFlux_1_1IO_a582f5249ec35cc284ce9e293ef33d9ce.html#a582f5249ec35cc284ce9e293ef33d9ce">MayaFlux::IO::FileReadOptions</a></div><div class="ttdeci">FileReadOptions</div><div class="ttdoc">Generic options for file reading behavior.</div><div class="ttdef"><b>Definition</b> <a href="FileReader_8hpp_source.html#l00060">FileReader.hpp:60</a></div></div>
<div class="ttc" id="anamespaceMayaFlux_1_1IO_a582f5249ec35cc284ce9e293ef33d9ce_html_a582f5249ec35cc284ce9e293ef33d9cea2e5626de6a522fd3e19b15f26dd26293"><div class="ttname"><a href="namespaceMayaFlux_1_1IO_a582f5249ec35cc284ce9e293ef33d9ce.html#a582f5249ec35cc284ce9e293ef33d9cea2e5626de6a522fd3e19b15f26dd26293">MayaFlux::IO::FileReadOptions::EXTRACT_METADATA</a></div><div class="ttdeci">@ EXTRACT_METADATA</div><div class="ttdoc">Extract file metadata.</div></div>
</div><!-- fragment --><p>Depending on your exposure to programming, this can either feel complex or liberating. Lacking the facilities to be explicit about memory management or allocation can be limiting:</p>
<ul>
<li>Not knowing when memory is created, bound, or cleared</li>
<li>Realizing too late that your memory usage is exceeding the budget</li>
<li>Slowing the system for the false simplicity of “available without effort” These often lead to confinement and confusion.</li>
</ul>
<p>However, the above code snippet is verbose for something so simple.</p>
<p><code>vega</code> says: "You just want to load a file? Say so."</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> sound_container = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a8437a7d641c0011d359c38f13881adc0.html#a8437a7d641c0011d359c38f13881adc0">read_audio</a>(<span class="stringliteral">&quot;file.wav&quot;</span>);</div>
</div><!-- fragment --><p>Same machinery underneath. Same FFmpeg integration. Same resampling. Same deinterleaving. Same processor setup. Same safety.</p>
<p><b>What <code>vega</code> does:</b></p>
<ul>
<li>Infers format from filename extension</li>
<li>Initializes the reader with sensible defaults</li>
<li>Handles error checking internally</li>
<li>Constructs the Container correctly</li>
<li>Configures the processor</li>
<li>Returns the result</li>
</ul>
<p><b>What <code>vega</code> doesn't do:</b></p>
<ul>
<li>Hide the complexity. It subsumes the <em>verbosity</em>, not the <em>idea</em>.</li>
<li>Make the Container less capable. It's the full Container with all features.</li>
<li>Remove your ability to do this explicitly. You can always write the long version if you need control.</li>
</ul>
<p>The short syntax is convenience. The long syntax is control. <a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a> gives you both.</p>
<p></p>
</details>
<p>Use <code>vega</code> because you value fluency, not because you fear the machinery.</p>
<h2><a class="anchor" id="autotoc_md461"></a>
Expansion 4: The Container's Processor</h2>
<details >
<summary >
Details</summary>
<p>&lt;parameter name="open"&gt;</p>
<p>The Container you just created isn't just a data holder. It has a **default processor**—a piece of machinery attached to it that knows how to feed data to buffers.</p>
<p>This processor (<code><a class="el" href="classContiguousAccessProcessor.html" title="Data Processor for efficient, sequential access to N-dimensional data containers.">ContiguousAccessProcessor</a></code>) does crucial work:</p>
<ol type="1">
<li><b>Understands the memory layout</b> - how the Container's audio data is organized</li>
<li><b>Knows the buffer size</b> - how many samples to chunk at a time (typically 512 or 4096)</li>
<li><b>Tracks position</b> - where in the file you are (auto-advance means it moves forward each time data is requested)</li>
<li><b>Deinterleaves access</b> - gives channels separately (crucial for processing, as you can transform each channel independently)</li>
</ol>
<p>When you later connect this Container to buffers (in the next section), the processor is what actually feeds the data—it’s the active mechanism.</p>
<p><code>vega.read_audio()</code> configures this processor automatically:</p>
<ul>
<li>Sets output size to your project's buffer size</li>
<li>Enables auto-advance (keeps moving through the file)</li>
<li>Registers it with the Container</li>
</ul>
<p>This is why <code>StreamContainers</code> (that <code>SoundFileContainer</code> inherits from) are more than data—they're <em>active</em>, with built-in logic for how they should be consumed.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md462"></a>
Expansion 5: What &lt;tt&gt;.read_audio()&lt;/tt&gt; Does NOT Do</h2>
<details >
<summary >
Details</summary>
<p>&lt;parameter name="open"&gt;</p>
<p>This is important:</p>
<p>**<code>.read_audio()</code> does NOT:**</p>
<ul>
<li>Start playback</li>
<li>Create buffers</li>
<li>Connect to your audio hardware</li>
<li>Route data anywhere</li>
</ul>
<p>**<code>.read_audio()</code> DOES:**</p>
<ul>
<li>Read file from disk</li>
<li>Decode audio (handle any format: WAV, MP3, FLAC, etc. via FFmpeg)</li>
<li>Resample to your project's sample rate</li>
<li>Allocate memory for all samples</li>
<li>Deinterleave channels</li>
<li>Attach a processor that knows how to access this data</li>
<li>Return you a Container</li>
</ul>
<p>The Container sits in memory, ready to be used. But “ready to be used” means you decide what happens next: process it, analyze it, route it to output or visual processing, feed it into a machine-learning pipeline, anything.</p>
<p><b>That’s the power of this design</b>: loading is separate from routing. You can load a file and immediately send it to hardware, or spend the next 20 lines building a complex processing pipeline before ever playing it.</p>
<p></p>
</details>
<hr  />
<p>In the next section, we'll connect this Container to buffers and route it to your speakers. And you'll see why this two-step design—load, then connect—is more powerful than one-step automatic playback.</p>
<hr  />
<h1><a class="anchor" id="autotoc_md465"></a>
Tutorial: Connect to Buffers</h1>
<h2><a class="anchor" id="autotoc_md466"></a>
The Next Step</h2>
<p>You have a Container loaded. Now you need to send it somewhere.</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> sound_container = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a8437a7d641c0011d359c38f13881adc0.html#a8437a7d641c0011d359c38f13881adc0">read_audio</a>(<span class="stringliteral">&quot;path/to/file.wav&quot;</span>);</div>
<div class="line"><span class="keyword">auto</span> buffers = <a class="code hl_function" href="namespaceMayaFlux_adfd1764a90716b65f56ed3647851c96a.html#adfd1764a90716b65f56ed3647851c96a">MayaFlux::hook_sound_container_to_buffers</a>(sound_container);</div>
<div class="ttc" id="anamespaceMayaFlux_adfd1764a90716b65f56ed3647851c96a_html_adfd1764a90716b65f56ed3647851c96a"><div class="ttname"><a href="namespaceMayaFlux_adfd1764a90716b65f56ed3647851c96a.html#adfd1764a90716b65f56ed3647851c96a">MayaFlux::hook_sound_container_to_buffers</a></div><div class="ttdeci">std::vector&lt; std::shared_ptr&lt; Buffers::SoundContainerBuffer &gt; &gt; hook_sound_container_to_buffers(const std::shared_ptr&lt; MayaFlux::Kakshya::SoundFileContainer &gt; &amp;container)</div><div class="ttdoc">Connects a SoundFileContainer to the buffer system for immediate playback.</div><div class="ttdef"><b>Definition</b> <a href="Depot_8cpp_source.html#l00084">Depot.cpp:84</a></div></div>
</div><!-- fragment --><p>Run this code. Your file plays.</p>
<p>The Container + the hook call—together they form the path from disk to speakers. This section shows you what that connection does.</p>
<h2><a class="anchor" id="autotoc_md467"></a>
Expansion 1: What Are Buffers?</h2>
<details >
<summary >
Click to expand: Understanding Buffers</summary>
<p></p>
<p>A <b>Buffer</b> is a temporal accumulator—a space where data gathers until it's ready to be released, then it resets and gathers again.</p>
<p>Buffers don't store your entire file. They store chunks. At your project's sample rate (48 kHz), a typical buffer might hold 512 or 4096 samples: a handful of milliseconds of audio.</p>
<p>Here's why this matters:</p>
<p>Your audio interface (speakers, headphones) has a fixed callback rate. It says: "Give me 512 samples of audio, and do it every 10 milliseconds. Repeat forever until playback stops."</p>
<p>Buffers are the industry standard method to meet this demand.</p>
<ol type="1">
<li><b>Gathers</b> - accumulates samples from your Container (via its processor)</li>
<li><b>Holds</b> - keeps those samples temporarily</li>
<li><b>Releases</b> - sends them to hardware</li>
<li><b>Resets</b> - becomes empty and ready for the next chunk</li>
</ol>
<p>This cycle repeats thousands of times per minute. Buffers make that possible.</p>
<p>Without buffers, you'd have to manually manage these chunks yourself. With buffers, <a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a> handles the cycle. Your Container's processor feeds data into them. The buffers exhale it to your ears.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md468"></a>
Expansion 2: Why Per-Channel Buffers?</h2>
<details >
<summary >
Click to expand: Stereo, Mono, and Channel Architecture</summary>
<p></p>
<p>A stereo file has 2 channels. A multichannel file might have 4 or 8 channels. <a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a> doesn't merge them into one buffer.</p>
<p>Instead, it creates <b>one buffer per channel</b>.</p>
<p>Why? Because channels are independent processing domains. A stereo file's left channel and right channel:</p>
<ul>
<li>Can be processed differently</li>
<li>Can be routed to different outputs</li>
<li>Can have different process chains</li>
<li>Can be analyzed separately</li>
<li>Can coordinate with each other without conflict</li>
</ul>
<p>When you hook a stereo Container to buffers, <a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a> creates:</p>
<ul>
<li>Buffer for channel 0 (left)</li>
<li>Buffer for channel 1 (right)</li>
</ul>
<p>Each buffer:</p>
<ul>
<li>Pulls samples from the Container's channel 0 or channel 1 (via the Container's processor)</li>
<li>Gets filled with 512/4096/etc. samples</li>
<li>Sends those samples to the audio interface's corresponding output</li>
</ul>
<p>This per-channel design is why you can later insert processing on a per-channel basis. Insert a filter on channel 0? The first channel gets filtered. Leave channel 1 alone? The second channel plays unprocessed. This flexibility is only possible because channels are architecturally separate at the buffer level.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md469"></a>
Expansion 3: The Buffer Manager and Buffer Lifecycle</h2>
<details >
<summary >
Click to expand: How Buffers Are Created and Managed</summary>
<p></p>
<p><a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a> has a **buffer manager**—a central system that creates, tracks, and coordinates all buffers in your program.</p>
<p>When you call <code>hook_sound_container_to_buffers()</code>, here's what happens:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> buffer_manager = <a class="code hl_function" href="namespaceMayaFlux_ab62f030499d58eb3e1d5c43ca3bc230e.html#ab62f030499d58eb3e1d5c43ca3bc230e">MayaFlux::get_buffer_manager</a>();</div>
<div class="line">uint32_t num_channels = container-&gt;get_num_channels();</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">for</span> (uint32_t channel = 0; channel &lt; num_channels; ++channel) {</div>
<div class="line">    <span class="keyword">auto</span> container_buffer = buffer_manager-&gt;create_audio_buffer&lt;SoundContainerBuffer&gt;(</div>
<div class="line">        ProcessingToken::AUDIO_BACKEND,</div>
<div class="line">        channel,</div>
<div class="line">        container,</div>
<div class="line">        channel);</div>
<div class="line">    container_buffer-&gt;initialize();</div>
<div class="line">}</div>
<div class="ttc" id="anamespaceMayaFlux_ab62f030499d58eb3e1d5c43ca3bc230e_html_ab62f030499d58eb3e1d5c43ca3bc230e"><div class="ttname"><a href="namespaceMayaFlux_ab62f030499d58eb3e1d5c43ca3bc230e.html#ab62f030499d58eb3e1d5c43ca3bc230e">MayaFlux::get_buffer_manager</a></div><div class="ttdeci">std::shared_ptr&lt; Buffers::BufferManager &gt; get_buffer_manager()</div><div class="ttdoc">Gets the buffer manager from the default engine.</div><div class="ttdef"><b>Definition</b> <a href="Graph_8cpp_source.html#l00131">Graph.cpp:131</a></div></div>
</div><!-- fragment --><p>Step by step:</p>
<ol type="1">
<li><b>Get the buffer manager</b> - a global system that owns all buffers</li>
<li><b>Ask the Container: how many channels?</b> - determines the loop count</li>
<li><b>For each channel:</b><ul>
<li>Create an audio buffer of type <code>SoundContainerBuffer</code> (a buffer that reads from a Container)</li>
<li>Tag it with <code>AUDIO_BACKEND</code> (more on this in Expansion 5)</li>
<li>Tell it which channel matrix the buffer should belongs to</li>
<li>Tell it which channel in the Container to read from</li>
<li>Initialize it (prepare it for the callback cycle)</li>
</ul>
</li>
</ol>
<p>Now the buffer manager knows:</p>
<ul>
<li>These buffers exist</li>
<li>These buffers are tied to this Container</li>
<li>These buffers should feed the audio hardware</li>
<li>These buffers are ready to cycle</li>
</ul>
<p>When the audio callback fires (every 10ms at 48 kHz), the buffer manager wakes up all its <code>AUDIO_BACKEND</code> buffers and says: "Time for the next chunk. Fill yourselves."</p>
<p>Each buffer asks its Container's processor: "Give me 512 samples from your channel."</p>
<p>The processor pulls from the Container, advances its position, and hands back a chunk.</p>
<p>The buffer receives it and passes it to the audio interface.</p>
<p>Repeat forever.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md470"></a>
Expansion 4: SoundContainerBuffer—The Bridge</h2>
<details >
<summary >
Click to expand: How Buffers Know Their Source</summary>
<p></p>
<p>You created a <code>SoundContainerBuffer</code>, not just a generic <code>Buffer</code>. Why the distinction?</p>
<p>A <b>Buffer</b> is abstract—it's a temporal accumulator. But abstract things don't know where their data comes from.</p>
<p>A <b>SoundContainerBuffer</b> is specific—it's a buffer that knows:</p>
<ul>
<li>"My data comes from a Container"</li>
<li>"My Container has a processor that chunks data"</li>
<li>"I ask that processor for samples from a specific channel"</li>
</ul>
<p>When the callback fires, the SoundContainerBuffer doesn't generate samples. It asks: "Container, give me the next 512 samples from your channel 0."</p>
<p>The Container's processor (remember <code><a class="el" href="classContiguousAccessProcessor.html" title="Data Processor for efficient, sequential access to N-dimensional data containers.">ContiguousAccessProcessor</a></code> from Section 1?) handles this. It:</p>
<ul>
<li>Knows where in the file you are (it tracks position)</li>
<li>Knows how much data to chunk (512 samples)</li>
<li>Pulls that many samples from its memory</li>
<li>Auto-advances (moves the position forward)</li>
<li>Returns the chunk</li>
</ul>
<p>The SoundContainerBuffer receives it. Done.</p>
<p>This is the architecture: <b>Buffers don't generate or transform. They request and relay.</b> The Container's processor does the work. The buffer coordinates timing with hardware.</p>
<p>Later, when you add processing nodes or attach processing chains, you'll insert them between the Container's output and the buffer's input. The buffer still doesn't transform—it still just relays. But what it relays will have been processed first.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md471"></a>
Expansion 5: Processing Token—AUDIO_BACKEND</h2>
<details >
<summary >
Click to expand: Tokens, Domains, and Hardware Destinations</summary>
<p></p>
<p>In the buffer creation code:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> container_buffer = buffer_manager-&gt;create_audio_buffer&lt;SoundContainerBuffer&gt;(</div>
<div class="line">    ProcessingToken::AUDIO_BACKEND,</div>
<div class="line">    channel,</div>
<div class="line">    container,</div>
<div class="line">    channel);</div>
</div><!-- fragment --><p>Notice <code>ProcessingToken::AUDIO_BACKEND</code>. This is a **token**—a semantic marker that tells <a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a>:</p>
<ul>
<li><b>This buffer is audio-domain</b> (not graphics, not compute)</li>
<li><b>This buffer is connected to the hardware backend</b> (it's the final destination before speakers)</li>
<li><b>This buffer runs at audio callback rate</b> (every ~10ms at 48 kHz, every 512 samples)</li>
<li><b>This buffer synchronizes with the real-time audio clock</b></li>
</ul>
<p>Tokens are how <a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a> coordinates different processing domains without confusion. Later, you might have:</p>
<ul>
<li><code>AUDIO_BACKEND</code> buffers - connected to speakers (hardware real-time)</li>
<li><code>AUDIO_PARALLEL</code> buffers - internal processing (process chains, analysis, etc.)</li>
<li><code>GRAPHICS_BACKEND</code> buffers - visual domain (frame-rate, not sample-rate)</li>
</ul>
<p>Each token tells the system what timing, synchronization, and backend this buffer belongs to.</p>
<p>For now: <code>AUDIO_BACKEND</code> means "this buffer is feeding your ears directly. It must keep real-time pace with the audio interface."</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md472"></a>
Expansion 6: Accessing the Buffers</h2>
<details >
<summary >
Click to expand: What You Can Do With the Buffers</summary>
<p></p>
<p>When you call <code>vega.read_audio() | Audio</code>, <a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a> creates the buffers internally. But now, with the ability to get those buffers back, you have access to them:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> sound_container = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a8437a7d641c0011d359c38f13881adc0.html#a8437a7d641c0011d359c38f13881adc0">read_audio</a>(<span class="stringliteral">&quot;path/to/file.wav&quot;</span>);</div>
<div class="line"><span class="keyword">auto</span> buffers = <a class="code hl_function" href="namespaceMayaFlux_a16a769fcbec756197086526ac9297aa8.html#a16a769fcbec756197086526ac9297aa8">MayaFlux::get_last_created_container_buffers</a>();</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Now you have the buffers as a vector:</span></div>
<div class="line"><span class="comment">// buffers[0] → channel 0</span></div>
<div class="line"><span class="comment">// buffers[1] → channel 1 (if stereo)</span></div>
<div class="line"><span class="comment">// etc.</span></div>
<div class="ttc" id="anamespaceMayaFlux_a16a769fcbec756197086526ac9297aa8_html_a16a769fcbec756197086526ac9297aa8"><div class="ttname"><a href="namespaceMayaFlux_a16a769fcbec756197086526ac9297aa8.html#a16a769fcbec756197086526ac9297aa8">MayaFlux::get_last_created_container_buffers</a></div><div class="ttdeci">std::vector&lt; std::shared_ptr&lt; Buffers::SoundContainerBuffer &gt; &gt; get_last_created_container_buffers()</div><div class="ttdoc">Retrieves the last created container buffers from the Creator.</div><div class="ttdef"><b>Definition</b> <a href="Creator_8cpp_source.html#l00105">Creator.cpp:105</a></div></div>
</div><!-- fragment --><p>Why is this useful? Because buffers own <b>processing chains</b>. And processing chains are where you'll insert processes, analysis, transformations - everything that turns passive playback into active processing.</p>
<p>Each buffer has a method:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> chain = buffers[0]-&gt;get_processing_chain();</div>
</div><!-- fragment --><p>This gives you access to the chain that currently handles that buffer's data. Right now, the chain just reads from the Container and writes to the hardware. But you can modify that chain.</p>
<ul>
<li>Add processors.</li>
<li>Analyze data.</li>
<li>Route to different destinations.</li>
</ul>
<p>This is the foundation for Section 3. You load a file, get the buffers, access their chains, and inject processing into those chains.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md473"></a>
&lt;/details&gt;</h2>
<h2><a class="anchor" id="autotoc_md474"></a>
The Fluent vs. Explicit Comparison</h2>
<h3><a class="anchor" id="autotoc_md475"></a>
Fluent (What happens behind the scenes)</h3>
<div class="fragment"><div class="line">vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a8437a7d641c0011d359c38f13881adc0.html#a8437a7d641c0011d359c38f13881adc0">read_audio</a>(<span class="stringliteral">&quot;path/to/file.wav&quot;</span>) | Audio;</div>
</div><!-- fragment --><p>This single line does all of the above: creates a Container, creates per-channel buffers, hooks them to the audio hardware, and starts playback. No file plays until the <code>| Audio</code> operator, which is when the connection happens.</p>
<h3><a class="anchor" id="autotoc_md476"></a>
Explicit (What's actually happening)</h3>
<div class="fragment"><div class="line"><span class="keyword">auto</span> sound_container = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a8437a7d641c0011d359c38f13881adc0.html#a8437a7d641c0011d359c38f13881adc0">read_audio</a>(<span class="stringliteral">&quot;path/to/file.wav&quot;</span>);</div>
<div class="line"><span class="keyword">auto</span> buffers = <a class="code hl_function" href="namespaceMayaFlux_a16a769fcbec756197086526ac9297aa8.html#a16a769fcbec756197086526ac9297aa8">MayaFlux::get_last_created_container_buffers</a>();</div>
<div class="line"><span class="comment">// File is loaded, buffers exist, but no connection to hardware yet</span></div>
<div class="line"><span class="comment">// Buffers have chains, but nothing is using them</span></div>
<div class="line"> </div>
<div class="line"><span class="comment">// To actually play, you&#39;d need to ensure they&#39;re registered</span></div>
<div class="line"><span class="comment">// (vega.read_audio() | Audio does this automatically)</span></div>
</div><!-- fragment --><p><b>Understanding the difference:</b></p>
<ul>
<li>The fluent version (<code>| Audio</code>) triggers buffer creation <em>and</em> hardware connection</li>
<li>The explicit version gives you the buffers so you can inspect and modify them <em>before</em> hooking to hardware</li>
<li>Both do the same thing—one is convenience, one is control</li>
</ul>
<hr  />
<h2><a class="anchor" id="autotoc_md478"></a>
Try It</h2>
<div class="fragment"><div class="line"><span class="keywordtype">void</span> compose() {</div>
<div class="line">    vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a8437a7d641c0011d359c38f13881adc0.html#a8437a7d641c0011d359c38f13881adc0">read_audio</a>(<span class="stringliteral">&quot;path/to/your/file.wav&quot;</span>) | Audio;</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// File plays</span></div>
<div class="line">}</div>
</div><!-- fragment --><p>Replace <code>"path/to/your/file.wav"</code> with an actual path.</p>
<p>You have:</p>
<ul>
<li>A Container loaded with all audio data (deinterleaved, resampled, ready)</li>
<li>Per-channel buffers created, each tied to a Container channel</li>
<li>Buffers registered with the buffer manager and audio interface</li>
<li>The callback cycle running, continuously pulling chunks and feeding them to speakers</li>
<li>Your file plays start-to-finish automatically</li>
</ul>
<p>No code running during playback—just the callback cycle doing its work, thousands of times per minute.</p>
<p>In the next section, we'll modify these buffers' processing chains. We'll insert a filter processor and hear how it changes the sound. This is where <a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a>'s power truly shines—transforming passive playback into active, real-time audio processing.</p>
<hr  />
<h1><a class="anchor" id="autotoc_md480"></a>
Tutorial: Buffers Own Chains</h1>
<h2><a class="anchor" id="autotoc_md481"></a>
The Simplest Path</h2>
<p>You have buffers. You can modify what flows through them.</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> sound_container = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a8437a7d641c0011d359c38f13881adc0.html#a8437a7d641c0011d359c38f13881adc0">read_audio</a>(<span class="stringliteral">&quot;path/to/file.wav&quot;</span>) | Audio;</div>
<div class="line"><span class="keyword">auto</span> buffers = <a class="code hl_function" href="namespaceMayaFlux_a16a769fcbec756197086526ac9297aa8.html#a16a769fcbec756197086526ac9297aa8">MayaFlux::get_last_created_container_buffers</a>();</div>
<div class="line"> </div>
<div class="line"><span class="keyword">auto</span> filter = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a4d7d43fd4040c892d45d17d29fbe1de8.html#a4d7d43fd4040c892d45d17d29fbe1de8">IIR</a>({0.1, 0.2, 0.1}, {1.0, -0.6});</div>
<div class="line"><span class="keyword">auto</span> filter_processor = MayaFlux::create_processor&lt;MayaFlux::Buffers::FilterProcessor&gt;(buffers[0], filter);</div>
<div class="ttc" id="aclassMayaFlux_1_1Creator_a4d7d43fd4040c892d45d17d29fbe1de8_html_a4d7d43fd4040c892d45d17d29fbe1de8"><div class="ttname"><a href="classMayaFlux_1_1Creator_a4d7d43fd4040c892d45d17d29fbe1de8.html#a4d7d43fd4040c892d45d17d29fbe1de8">MayaFlux::Creator::IIR</a></div><div class="ttdeci">auto IIR(Args &amp;&amp;... args) -&gt; CreationHandle&lt; MayaFlux::Nodes::Filters::IIR &gt;</div><div class="ttdef"><b>Definition</b> <a href="Creator_8hpp_source.html#l00190">Creator.hpp:190</a></div></div>
</div><!-- fragment --><p>Run this code. Your file plays with a low-pass filter applied.</p>
<p>The filter smooths the audio—reduces high frequencies. Listen to the difference.</p>
<p>That's it. Three lines of code: load, get buffers, insert filter. The rest of this section shows you what just happened.</p>
<h2><a class="anchor" id="autotoc_md482"></a>
Expansion 1: What Is &lt;tt&gt;vega.IIR()&lt;/tt&gt;?</h2>
<details >
<summary >
Click to expand: Creating Filter Nodes</summary>
<p></p>
<p><code>vega.IIR()</code> creates a filter node—a computation unit that processes audio samples one at a time.</p>
<p>An <b>IIR filter</b> (Infinite Impulse Response) is a mathematical operation that transforms samples based on feedback coefficients. The two parameters are:</p>
<ul>
<li><b>Feedforward coefficients</b> <code>{0.1, 0.2, 0.1}</code> - how the current and past input samples contribute</li>
<li><b>Feedback coefficients</b> <code>{1.0, -0.6}</code> - how past output samples contribute</li>
</ul>
<p>You don't need to understand the math. Just know: this creates a filter that smooths audio.</p>
<p><code>vega</code> is the fluent interface—it subsumes verbosity. Without it:</p>
<div class="fragment"><div class="line"><span class="comment">// Without vega - explicit</span></div>
<div class="line"><span class="keyword">auto</span> filter = std::make_shared&lt;Nodes::Filters::IIR&gt;(</div>
<div class="line">    std::vector&lt;double&gt;{0.1, 0.2, 0.1},</div>
<div class="line">    std::vector&lt;double&gt;{1.0, -0.6}</div>
<div class="line">);</div>
</div><!-- fragment --><p>With vega:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> filter = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a4d7d43fd4040c892d45d17d29fbe1de8.html#a4d7d43fd4040c892d45d17d29fbe1de8">IIR</a>({0.1, 0.2, 0.1}, {1.0, -0.6});</div>
</div><!-- fragment --><p>Same filter. Same capabilities. Vega just hides the verbosity.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md483"></a>
Expansion 2: What Is &lt;tt&gt;MayaFlux::create_processor()&lt;/tt&gt;?</h2>
<details >
<summary >
Click to expand: Wrapping Nodes in Processors</summary>
<p></p>
<p>A <b>node</b> (like <code>vega.IIR()</code>) is a computational unit—it processes one sample at a time.</p>
<p>This <b>processor</b> is a buffer-aware wrapper around that node. It knows:</p>
<ul>
<li>How to extract data from a buffer</li>
<li>How to feed samples to the node</li>
<li>How to put the transformed samples back in the buffer</li>
<li>How to handle the buffer's processing cycle</li>
</ul>
<p><code>create_processor()</code> wraps your filter node in a processor and attaches it to a buffer's processing chain.</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> filter_processor = MayaFlux::create_processor&lt;MayaFlux::Buffers::FilterProcessor&gt;(buffers[0], filter);</div>
</div><!-- fragment --><p>What this does:</p>
<ol type="1">
<li>Takes your filter node</li>
<li>Creates a <code>FilterProcessor</code> that knows how to apply that node to buffer data</li>
<li>Adds the processor to <code>buffers[0]</code>'s processing chain (implicit—this happens automatically)</li>
<li>Returns the processor so you can reference it later if needed</li>
</ol>
<p>The buffer now has this processor in its chain. Each cycle, the buffer runs the processor, which applies the filter to all samples in that cycle.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md484"></a>
Expansion 3: What Is a Processing Chain?</h2>
<details >
<summary >
Click to expand: How Buffers Execute Processors</summary>
<p></p>
<p>Each buffer owns a **processing chain**—an ordered sequence of processors that transform data.</p>
<p>Your buffer's default processor was:</p>
<ul>
<li><b>SoundStreamReader</b> - reads from the Container, fills the buffer</li>
</ul>
<p>When <code>create_processor()</code> adds your FilterProcessor, the chain becomes:</p>
<ol type="1">
<li>Default processor: SoundStreamReader (reads from Container)</li>
<li><b>FilterProcessor</b> (applies your filter) ← You just added this</li>
<li>Other processors you might add later (e.g., Writer to send to hardware)</li>
</ol>
<p>Each cycle:</p>
<ul>
<li>Adapter fills the buffer with 512 samples from the Container</li>
<li>FilterProcessor runs—modifies those 512 samples by applying the filter</li>
<li>Other processors run in sequence</li>
</ul>
<p>Data flows: <b>Container → [filtered] → Speakers</b></p>
<p>The chain is ordered. Processors run in sequence. Output of one becomes input to next.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md485"></a>
Expansion 4: Adding Processor to Another Channel (Optional)</h2>
<details >
<summary >
Click to expand: Multi-Channel Processing</summary>
<p></p>
<p>Your stereo file has two channels. Right now, only channel 0 is filtered.</p>
<p>You can add the same processor to channel 1:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> filter = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a4d7d43fd4040c892d45d17d29fbe1de8.html#a4d7d43fd4040c892d45d17d29fbe1de8">IIR</a>({0.1, 0.2, 0.1}, {1.0, -0.6});</div>
<div class="line"><span class="keyword">auto</span> fp0 = MayaFlux::create_processor&lt;MayaFlux::Buffers::FilterProcessor&gt;(buffers[0], filter);</div>
<div class="line"><span class="keyword">auto</span> fp1 = MayaFlux::create_processor&lt;MayaFlux::Buffers::FilterProcessor&gt;(buffers[1], filter);</div>
</div><!-- fragment --><p>Or more simply, add the existing processor to another buffer:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> filter = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a4d7d43fd4040c892d45d17d29fbe1de8.html#a4d7d43fd4040c892d45d17d29fbe1de8">IIR</a>({0.1, 0.2, 0.1}, {1.0, -0.6});</div>
<div class="line"><span class="keyword">auto</span> filter_processor = MayaFlux::create_processor&lt;MayaFlux::Buffers::FilterProcessor&gt;(buffers[0], filter);</div>
<div class="line"><a class="code hl_function" href="namespaceMayaFlux_a4ccb7fdcd10c1cceabb85ea456ded3cb.html#a4ccb7fdcd10c1cceabb85ea456ded3cb">MayaFlux::add_processor</a>(filter_processor, buffers[1], <a class="code hl_enumvalue" href="namespaceMayaFlux_1_1Buffers_a3cd507bee892de0c2a998afb5acaed1c.html#a3cd507bee892de0c2a998afb5acaed1ca3316313471bb41d56b6b4f779a37a81d">MayaFlux::Buffers::ProcessingToken::AUDIO_BACKEND</a>);</div>
<div class="ttc" id="anamespaceMayaFlux_1_1Buffers_a3cd507bee892de0c2a998afb5acaed1c_html_a3cd507bee892de0c2a998afb5acaed1ca3316313471bb41d56b6b4f779a37a81d"><div class="ttname"><a href="namespaceMayaFlux_1_1Buffers_a3cd507bee892de0c2a998afb5acaed1c.html#a3cd507bee892de0c2a998afb5acaed1ca3316313471bb41d56b6b4f779a37a81d">MayaFlux::Buffers::AUDIO_BACKEND</a></div><div class="ttdeci">@ AUDIO_BACKEND</div><div class="ttdoc">Standard audio processing backend configuration.</div><div class="ttdef"><b>Definition</b> <a href="ProcessingTokens_8hpp_source.html#l00152">ProcessingTokens.hpp:152</a></div></div>
<div class="ttc" id="anamespaceMayaFlux_a4ccb7fdcd10c1cceabb85ea456ded3cb_html_a4ccb7fdcd10c1cceabb85ea456ded3cb"><div class="ttname"><a href="namespaceMayaFlux_a4ccb7fdcd10c1cceabb85ea456ded3cb.html#a4ccb7fdcd10c1cceabb85ea456ded3cb">MayaFlux::add_processor</a></div><div class="ttdeci">void add_processor(const std::shared_ptr&lt; Buffers::BufferProcessor &gt; &amp;processor, const std::shared_ptr&lt; Buffers::Buffer &gt; &amp;buffer, Buffers::ProcessingToken token)</div><div class="ttdoc">Adds a processor to a specific buffer.</div><div class="ttdef"><b>Definition</b> <a href="Graph_8cpp_source.html#l00136">Graph.cpp:136</a></div></div>
</div><!-- fragment --><p><code>add_processor()</code> adds an existing processor to a buffer's chain.</p>
<p><code>create_processor()</code> creates a processor and adds it implicitly.</p>
<p>Both do the same underlying thing—they add the processor to the buffer's chain. <code>create_processor()</code> just combines creation and addition in one call.</p>
<p>Now both channels are filtered by the same IIR node. Different channel buffers can share the same processor or have independent ones—your choice.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md486"></a>
Expansion 5: What Happens Inside</h2>
<details >
<summary >
Click to expand: The Machinery Under the Hood</summary>
<p></p>
<p>When you call:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> filter_processor = MayaFlux::create_processor&lt;MayaFlux::Buffers::FilterProcessor&gt;(buffers[0], filter);</div>
</div><!-- fragment --><p><a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a> does this:</p>
<div class="fragment"><div class="line"><span class="comment">// 1. Create a new FilterProcessor wrapping your filter node</span></div>
<div class="line"><span class="keyword">auto</span> processor = std::make_shared&lt;MayaFlux::Buffers::FilterProcessor&gt;(filter);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// 2. Get the buffer&#39;s processing chain</span></div>
<div class="line"><span class="keyword">auto</span> chain = buffers[0]-&gt;get_processing_chain();</div>
<div class="line"> </div>
<div class="line"><span class="comment">// 3. Add the processor to the chain</span></div>
<div class="line">chain-&gt;add_processor(processor, buffers[0]);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// 4. Return the processor</span></div>
<div class="line"><span class="keywordflow">return</span> processor;</div>
</div><!-- fragment --><p>When <code>add_processor()</code> is called separately:</p>
<div class="fragment"><div class="line"><a class="code hl_function" href="namespaceMayaFlux_a4ccb7fdcd10c1cceabb85ea456ded3cb.html#a4ccb7fdcd10c1cceabb85ea456ded3cb">MayaFlux::add_processor</a>(filter_processor, buffers[1], <a class="code hl_enumvalue" href="namespaceMayaFlux_1_1Buffers_a3cd507bee892de0c2a998afb5acaed1c.html#a3cd507bee892de0c2a998afb5acaed1ca3316313471bb41d56b6b4f779a37a81d">MayaFlux::Buffers::ProcessingToken::AUDIO_BACKEND</a>);</div>
</div><!-- fragment --><p><a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a> does this:</p>
<div class="fragment"><div class="line"><span class="comment">// Get the buffer manager</span></div>
<div class="line"><span class="keyword">auto</span> buffer_manager = <a class="code hl_function" href="namespaceMayaFlux_ab62f030499d58eb3e1d5c43ca3bc230e.html#ab62f030499d58eb3e1d5c43ca3bc230e">MayaFlux::get_buffer_manager</a>();</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Get channel 1&#39;s buffer for AUDIO_BACKEND token</span></div>
<div class="line"><span class="keyword">auto</span> buffer = buffer_manager-&gt;get_buffer(ProcessingToken::AUDIO_BACKEND, 1);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Get its processing chain</span></div>
<div class="line"><span class="keyword">auto</span> chain = buffer-&gt;get_processing_chain();</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Add the processor</span></div>
<div class="line">chain-&gt;add_processor(processor, buffer);</div>
</div><!-- fragment --><p>The machinery is consistent: <b>processors are added to chains, chains are owned by buffers, buffers execute chains each cycle.</b></p>
<p>You don't need to write this explicitly—the convenience functions handle it. But this is what's happening.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md487"></a>
Expansion 6: Processors Are Reusable Building Blocks</h2>
<details >
<summary >
Click to expand: Composition and Flexibility</summary>
<p></p>
<p>A processor is a building block. Once created, it can be:</p>
<ul>
<li>Added to multiple buffers (same processor, multiple channels)</li>
<li>Composed with other processors (insert multiple processors)</li>
<li>Swapped out (remove and replace)</li>
<li>Queried (ask for its state, parameters, etc.)</li>
</ul>
<p>Example: two channels with the same filter:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> filter = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a4d7d43fd4040c892d45d17d29fbe1de8.html#a4d7d43fd4040c892d45d17d29fbe1de8">IIR</a>({0.1, 0.2, 0.1}, {1.0, -0.6});</div>
<div class="line"><span class="keyword">auto</span> processor = MayaFlux::create_processor&lt;MayaFlux::Buffers::FilterProcessor&gt;(buffers[0], filter);</div>
<div class="line"><a class="code hl_function" href="namespaceMayaFlux_a4ccb7fdcd10c1cceabb85ea456ded3cb.html#a4ccb7fdcd10c1cceabb85ea456ded3cb">MayaFlux::add_processor</a>(processor, buffers[1]);</div>
</div><!-- fragment --><p>Example: stacking processors (requires understanding of chains, shown later):</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> filter1 = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a4d7d43fd4040c892d45d17d29fbe1de8.html#a4d7d43fd4040c892d45d17d29fbe1de8">IIR</a>(...);</div>
<div class="line"><span class="keyword">auto</span> fp1 = MayaFlux::create_processor&lt;MayaFlux::Buffers::FilterProcessor&gt;(buffers[0], filter1);</div>
<div class="line"> </div>
<div class="line"><span class="keyword">auto</span> filter2 = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a4d7d43fd4040c892d45d17d29fbe1de8.html#a4d7d43fd4040c892d45d17d29fbe1de8">IIR</a>(...); <span class="comment">// Different filter</span></div>
<div class="line"><span class="keyword">auto</span> fp2 = MayaFlux::create_processor&lt;MayaFlux::Buffers::FilterProcessor&gt;(buffers[0], filter2);</div>
</div><!-- fragment --><p>Now buffers[0] has two FilterProcessors in its chain. Data flows through both sequentially.</p>
<p>Processors are the creative atoms of <a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a>. Everything builds from them.</p>
<p></p>
</details>
<hr  />
<h2><a class="anchor" id="autotoc_md489"></a>
Try It</h2>
<div class="fragment"><div class="line"><span class="keywordtype">void</span> compose() {</div>
<div class="line">    <span class="keyword">auto</span> sound_container = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a8437a7d641c0011d359c38f13881adc0.html#a8437a7d641c0011d359c38f13881adc0">read_audio</a>(<span class="stringliteral">&quot;path/to/your/file.wav&quot;</span>) | Audio;</div>
<div class="line">    <span class="keyword">auto</span> buffers = <a class="code hl_function" href="namespaceMayaFlux_a16a769fcbec756197086526ac9297aa8.html#a16a769fcbec756197086526ac9297aa8">MayaFlux::get_last_created_container_buffers</a>();</div>
<div class="line"> </div>
<div class="line">    <span class="keyword">auto</span> filter = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a4d7d43fd4040c892d45d17d29fbe1de8.html#a4d7d43fd4040c892d45d17d29fbe1de8">IIR</a>({0.1, 0.2, 0.1}, {1.0, -0.6});</div>
<div class="line">    <span class="keyword">auto</span> filter_processor = MayaFlux::create_processor&lt;MayaFlux::Buffers::FilterProcessor&gt;(buffers[0], filter);</div>
<div class="line">}</div>
</div><!-- fragment --><p>Replace <code>"path/to/your/file.wav"</code> with an actual path.</p>
<p>Run the program. Listen. The audio is filtered.</p>
<p>Now try modifying the coefficients:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> filter = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a4d7d43fd4040c892d45d17d29fbe1de8.html#a4d7d43fd4040c892d45d17d29fbe1de8">IIR</a>({0.05, 0.3, 0.05}, {1.0, -0.8});</div>
</div><!-- fragment --><p>Listen again. Different sound. You're sculpting the filter response.</p>
<p>You've just inserted a processor into a buffer's chain and heard the result. That's the foundation for everything that follows.</p>
<p>In the next section, we'll interrupt this passive playback. We'll insert a processing node between the Container and the buffers. And you'll see why this architecture—buffers as relays, not generators—enables powerful real-time transformation.</p>
<p>For a comprehensive tutorial on buffer processors and related concepts, visit the <a class="el" href="md_docs_2Tutorials_2SculptingData_2ProcessingExpression.html">Buffer Processors Tutorial</a>.</p>
<hr  />
<h1><a class="anchor" id="autotoc_md491"></a>
Tutorial: Timing, Streams, and Bridges</h1>
<h2><a class="anchor" id="autotoc_md492"></a>
The Current Continous Flow</h2>
<p>What you've done so far is simple and powerful:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> sound_container = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a8437a7d641c0011d359c38f13881adc0.html#a8437a7d641c0011d359c38f13881adc0">read_audio</a>(<span class="stringliteral">&quot;path/to/file.wav&quot;</span>) | Audio;</div>
<div class="line"><span class="keyword">auto</span> buffers = <a class="code hl_function" href="namespaceMayaFlux_a16a769fcbec756197086526ac9297aa8.html#a16a769fcbec756197086526ac9297aa8">MayaFlux::get_last_created_container_buffers</a>();</div>
<div class="line"><span class="keyword">auto</span> filter = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a4d7d43fd4040c892d45d17d29fbe1de8.html#a4d7d43fd4040c892d45d17d29fbe1de8">IIR</a>({0.1, 0.2, 0.1}, {1.0, -0.6});</div>
<div class="line"><span class="keyword">auto</span> fp = MayaFlux::create_processor&lt;MayaFlux::Buffers::FilterProcessor&gt;(buffers[0], filter);</div>
</div><!-- fragment --><p>This flow is designed for <b>full-file playback</b>:</p>
<ul>
<li>Load the entire file into a Container</li>
<li>route it through buffers</li>
<li>add general purpose processes</li>
<li>play to speakers (RtAudio backend via SubsystemManagers)</li>
</ul>
<p>Clean. Direct. No timing control.</p>
<p>That's intentional.</p>
<p>There are other features—region looping, seeking, playback control, but they don't fit this tutorial. These sections are purely for: <b>file → buffers → output, uninterrupted.</b></p>
<h2><a class="anchor" id="autotoc_md493"></a>
Where We're Going</h2>
<p>Here's what the next section enables:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> pipeline = <a class="code hl_function" href="namespaceMayaFlux_aa1955a73119c9e977f59ab989e74597e.html#aa1955a73119c9e977f59ab989e74597e">MayaFlux::create_buffer_pipeline</a>();</div>
<div class="line">pipeline-&gt;with_strategy(ExecutionStrategy::PHASED); <span class="comment">// Execute each phase fully before next op</span></div>
<div class="line"> </div>
<div class="line">pipeline</div>
<div class="line">    &gt;&gt; BufferOperation::capture_file_from(<span class="stringliteral">&quot;path/to/file.wav&quot;</span>, 0)  <span class="comment">// From channel 0</span></div>
<div class="line">    .for_cycles(20)  <span class="comment">// Process 20 buffer cycles</span></div>
<div class="line">    &gt;&gt; BufferOperation::transform([](<span class="keyword">auto</span>&amp; data, uint32_t cycle) {</div>
<div class="line">        <span class="comment">// Data now has 20 buffer cycles of audio from the file</span></div>
<div class="line">        <span class="comment">// i.e 20 x 512 samples if buffer size is 512</span></div>
<div class="line">        <span class="keyword">auto</span> zero_crossings = <a class="code hl_function" href="namespaceMayaFlux_a010207e20743bdaa60868cff23c0a8c5.html#a010207e20743bdaa60868cff23c0a8c5">MayaFlux::zero_crossings</a>(data);</div>
<div class="line"> </div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Zero crossings at indices:\n&quot;</span>;</div>
<div class="line">        <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; sample : zero_crossings) {</div>
<div class="line">            std::cout &lt;&lt; sample &lt;&lt; <span class="stringliteral">&quot;\t&quot;</span>;</div>
<div class="line">        }</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">        <span class="keywordflow">return</span> data;</div>
<div class="line">    });</div>
<div class="line"> </div>
<div class="line">pipeline-&gt;execute_buffer_rate();  <span class="comment">// Schedule and run</span></div>
<div class="ttc" id="anamespaceMayaFlux_a010207e20743bdaa60868cff23c0a8c5_html_a010207e20743bdaa60868cff23c0a8c5"><div class="ttname"><a href="namespaceMayaFlux_a010207e20743bdaa60868cff23c0a8c5.html#a010207e20743bdaa60868cff23c0a8c5">MayaFlux::zero_crossings</a></div><div class="ttdeci">std::vector&lt; size_t &gt; zero_crossings(const std::vector&lt; double &gt; &amp;data, double threshold)</div><div class="ttdoc">Detect zero crossings in single-channel signal.</div><div class="ttdef"><b>Definition</b> <a href="Yantra_8cpp_source.html#l00266">Yantra.cpp:266</a></div></div>
<div class="ttc" id="anamespaceMayaFlux_aa1955a73119c9e977f59ab989e74597e_html_aa1955a73119c9e977f59ab989e74597e"><div class="ttname"><a href="namespaceMayaFlux_aa1955a73119c9e977f59ab989e74597e.html#aa1955a73119c9e977f59ab989e74597e">MayaFlux::create_buffer_pipeline</a></div><div class="ttdeci">std::shared_ptr&lt; Kriya::BufferPipeline &gt; create_buffer_pipeline()</div><div class="ttdoc">Creates a new buffer pipeline instance.</div><div class="ttdef"><b>Definition</b> <a href="Chronie_8cpp_source.html#l00118">Chronie.cpp:118</a></div></div>
</div><!-- fragment --><p>This processes exactly 20 buffer cycles from the file (with any process you want), accumulates the result in a stream, and executes the pipeline.</p>
<p>The file isn't playing to speakers. It's being captured, processed, and stored in a stream. <b>Timing is under your control.</b>: You decide how many buffer cycles to process. This section builds the foundation for buffer pipelines. Understanding the architecture below explains why the code snippet works.</p>
<p>In this section, we will introduce the machinery for everything beyond simplicity. We're not building code that has audio yet. We're establishing the architecture that enables timing control, streaming, capture, and composition.</p>
<h2><a class="anchor" id="autotoc_md494"></a>
Expansion 1: The Architecture of Containers</h2>
<details >
<summary >
Click to expand: Why We Need Something Else</summary>
<p></p>
<p>A Container (like SoundFileContainer) holds all data upfront:</p>
<ul>
<li>Load entire file into memory</li>
<li>Data is fixed size</li>
<li>Processor knows where in the file you are</li>
<li>Designed for sequential access—read start, advance, read next chunk, repeat until end</li>
</ul>
<p>This works perfectly for "play the whole file". It also works for as yet unexpored controls over the same timeline, such as looping, seeking positions, jumping to regions, etc.</p>
<p>But it doesn't work for:</p>
<ul>
<li><b>Recording</b>: You don't know the final size upfront</li>
<li><b>Structuring</b>: You need to manipulate boundaries</li>
<li><b>Streaming</b>: Data arrives in chunks; size grows dynamically</li>
<li><b>Capture</b>: You want to save specific buffer cycles, not the whole file</li>
</ul>
<p>For these use cases, you need a different data structure.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md495"></a>
Expansion 2: Enter DynamicSoundStream</h2>
<details >
<summary >
Click to expand: A Container That Grows</summary>
<p></p>
<p>A <b>DynamicSoundStream</b> is a child class of <code>SignalSourceContainer</code> much like <code>SoundFileContainer</code> that we have been using. It has the same interface as <code>SoundFileContainer</code> (channels, frames, metadata, regions). But it has different semantics:</p>
<ul>
<li><b>Dynamic size</b>: Starts small, grows as data arrives</li>
<li><b>Transient modes</b>: Can operate as a circular buffer (fixed size, overwrites old data)</li>
<li><b>Sequential writing</b>: Designed to accept data sequentially from processors</li>
<li><b>No inherent structure</b>: Unlike SoundFileContainer (which knows "this is a file with a start and end"), DynamicSoundStream is just a growing reservoir of data.</li>
</ul>
<p>Think of it as:</p>
<ul>
<li><b>SoundFileContainer</b>: "I am this exact file, with this exact data"</li>
<li><b>DynamicSoundStream</b>: "I am a space where audio data accumulates. I don't know how much will arrive."</li>
</ul>
<p>DynamicSoundStream has powerful capabilities:</p>
<ul>
<li><b>Auto-resize mode</b>: Grows as data arrives (good for recording)</li>
<li><b>Circular mode</b>: Fixed capacity, wraps around (good for delay lines or rolling analysis)</li>
<li><b>Position tracking</b>: Knows where reads/writes are in the stream</li>
<li><b>Capacity pre-allocation</b>: You can reserve space if you know approximate size</li>
</ul>
<p>You don't create DynamicSoundStream directly (yet). It's managed implicitly by other systems. But understanding what it is explains everything that follows.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md496"></a>
Expansion 3: SoundStreamWriter</h2>
<details >
<summary >
Click to expand: Writing Buffer Data to Streams</summary>
<p></p>
<p>You've seen <code>BufferProcessors</code> like <code>FilterProcessor</code> that transform data in place.</p>
<p>But <code>SoundStreamWriter</code> is more general. It can write buffer data to <b>any</b> <code>DynamicSoundStream</code>, not just locally to attached buffers (or from hardware: hitherto unexplored <code>InputListenerProcessor</code>).</p>
<p>When a processor runs each buffer cycle:</p>
<ol type="1">
<li>Buffer gets filled with 512 samples (from Container or elsewhere)</li>
<li>Processors run (your <code>FilterProcessor</code>, for example)</li>
<li><code>SoundStreamWriter</code> writes the (now-processed) samples to a <code>DynamicSoundStream</code></li>
</ol>
<p>The <code>DynamicSoundStream</code> accumulates these writes:</p>
<ul>
<li>Cycle 1: 512 samples written</li>
<li>Cycle 2: Next 512 samples written (total: 1024)</li>
<li>Cycle 3: Next 512 samples written (total: 1536)</li>
<li>...</li>
</ul>
<p>After N cycles, the <code>DynamicSoundStream</code> contains N × 512 samples of processed audio.</p>
<p>This is how you capture buffer data. Not by sampling the buffer once, by continuously writing it to a stream through a processor.</p>
<p><code>SoundStreamWriter</code> is the bridge between buffers (which live in real-time) and streams (which accumulate).</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md497"></a>
Expansion 4: SoundFileBridge—Controlled Flow</h2>
<details >
<summary >
Click to expand: The Reading-Writing Bridge</summary>
<p></p>
<p><b>SoundFileBridge</b> is a specialized buffer that orchestrates reading from a file and writing to a stream, with timing control through buffer cycles.</p>
<p>Internally, SoundFileBridge creates a processing chain:</p>
<div class="fragment"><div class="line">SoundFileContainer (source file)</div>
<div class="line">    ↓</div>
<div class="line">SoundStreamReader (reads from file, advances position)</div>
<div class="line">    ↓</div>
<div class="line">[Your processors here: filters, etc.]</div>
<div class="line">    ↓</div>
<div class="line">SoundStreamWriter (writes to internal DynamicSoundStream)</div>
<div class="line">    ↓</div>
<div class="line">DynamicSoundStream (accumulates output)</div>
</div><!-- fragment --><p>The key difference from your simple load/play flow:</p>
<ul>
<li>Instead of routing to hardware, data goes to a DynamicSoundStream</li>
<li>You control <b>how many buffer cycles</b> run (e.g., "process 10 cycles of this file")</li>
<li>After N cycles, the stream holds N × buffer_size samples of the processed result</li>
</ul>
<p>SoundFileBridge represents: **"Read from this file, process through this chain, accumulate result in this stream, for exactly this many cycles."**</p>
<p>This gives you timing control. You don't play the whole file. You process exactly N cycles, then stop.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md498"></a>
Expansion 5: Why This Architecture?</h2>
<details >
<summary >
Click to expand: Decoupling Reading, Processing, and Output</summary>
<p></p>
<p>The architecture separates concerns:</p>
<ul>
<li><b>Reading</b>: Done by SoundStreamReader (reads from SoundFileContainer in controlled chunks)</li>
<li><b>Processing</b>: Done by your custom processors</li>
<li><b>Writing</b>: Done by SoundStreamWriter (writes results to DynamicSoundStream)</li>
<li><b>Accumulation</b>: Done by DynamicSoundStream (holds the result)</li>
</ul>
<p>Each layer is independent:</p>
<ul>
<li>You can swap the reader (use a different Container)</li>
<li>You can insert any number of processors</li>
<li>You can swap the writer (write to hardware, to disk, to memory, to GPU)</li>
<li>The stream is just a data holder—it doesn't care what filled it</li>
</ul>
<p>This is why SoundFileBridge is powerful: it composes these layers without forcing you to wire them manually.</p>
<p>And it's why understanding this section matters: <b>the next tutorial (BufferOperation) builds on top of this composition</b>, adding temporal coordination and pipeline semantics.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md499"></a>
Expansion 6: From File to Cycle</h2>
<details >
<summary >
Click to expand: "Cycles" as Timing Units</summary>
<p></p>
<p>A <b>cycle</b> is one complete buffer processing round:</p>
<ul>
<li>512 samples from the source</li>
<li>Processed through all processors</li>
<li>Written to the destination stream</li>
</ul>
<p>At 48 kHz, one cycle is 512 ÷ 48000 ≈ 10.67 milliseconds of audio.</p>
<p>When you say "process this file for 20 cycles," you mean:</p>
<ul>
<li>Run 20 iterations of: read 512 → process → write 512</li>
<li>Result: 10,240 samples (≈ 213 ms of audio at 48 kHz)</li>
</ul>
<p>Timing control is expressed in <b>cycles</b>, not time. This is intentional:</p>
<ul>
<li>Cycles are deterministic (you know exactly how much data will be processed)</li>
<li>Cycles are aligned with buffer boundaries (no partial processing)</li>
<li>Cycles decouple from hardware timing (no real-time constraints)</li>
</ul>
<p>SoundFileBridge lets you say: "Process this file for exactly N cycles," then accumulate the result in a stream.</p>
<p>This is the foundation for everything BufferOperation does—it extends this cycle-based thinking to composition and coordination.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md500"></a>
The Three Key Concepts</h2>
<p>At this point, understand:</p>
<ol type="1">
<li><b>DynamicSoundStream</b>: A container that grows dynamically, can operate in circular mode, designed to accumulate data from processors</li>
<li><b>SoundStreamWriter</b>: The processor that writes buffer data sequentially to a DynamicSoundStream</li>
<li><b>SoundFileBridge</b>: A buffer that creates a chain (reader → your processors → writer), and lets you control how many buffer cycles run</li>
</ol>
<p>These three concepts enable timing control. You're no longer at the mercy of real-time callbacks. You can process exactly N cycles, accumulate results, and move on.</p>
<h2><a class="anchor" id="autotoc_md501"></a>
Why This Section Has No Audio Code</h2>
<p>This is intentional. The concepts here are essential, and expose the architecture behind everything that follows. It is also a hint at the fact that modal output is not the only use case for <a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a>.</p>
<ul>
<li>SoundFileBridge is too low-level—you'd create it manually, call setup_chain_and_processor(), manage cycles yourself</li>
<li>DynamicSoundStream is too generic—without a driver, you'd just accumulate data with no purpose</li>
<li>SoundStreamWriter is just a piece—alone, it doesn't tell you how many cycles to run</li>
</ul>
<p>The <b>next tutorial introduces BufferOperation</b>, which wraps these concepts into high-level, composable patterns:</p>
<ul>
<li><code>BufferOperation::capture_file()</code> - wrap SoundFileBridge, accumulate N cycles, return the stream</li>
<li><code>BufferOperation::file_to_stream()</code> - connect file reading to stream writing, with cycle control</li>
<li><code>BufferOperation::route_to_container()</code> - send processor output to a stream</li>
</ul>
<p>Once you understand SoundFileBridge, DynamicSoundStream, and cycle-based timing, BufferOperation will feel natural. It's just syntactic sugar on top of this architecture.</p>
<p>For now: <b>internalize the architecture. The next section shows how to use it.</b></p>
<h2><a class="anchor" id="autotoc_md502"></a>
What You Should Internalize</h2>
<ul>
<li>Containers hold data (SoundFileContainer holds files; DynamicSoundStream holds growing data)</li>
<li>Processors transform data (your FilterProcessor, SoundStreamWriter, etc.)</li>
<li>Buffers orchestrate cycles (read N cycles, run processors, write results)</li>
<li>Streams accumulate (DynamicSoundStream holds results after cycles complete)</li>
<li>Timing is expressed in cycles (deterministic, aligned with buffer boundaries, decoupled from real-time)</li>
</ul>
<p>This is the mental model for everything that follows. Pipelines, capture, routing—they all build on this foundation.</p>
<hr  />
<h1><a class="anchor" id="autotoc_md504"></a>
Tutorial: Buffer Pipelines (Teaser)</h1>
<h2><a class="anchor" id="autotoc_md505"></a>
The Next Level</h2>
<p>Everything you've learned so far processes data in isolation: load a file, add a processor, output to hardware.</p>
<p>But what if you want to:</p>
<ul>
<li><b>Capture</b> a specific number of buffer cycles from a file</li>
<li><b>Process</b> those cycles through custom logic</li>
<li><b>Route</b> the result to a buffer for playback</li>
<li><b>Do all of this in one declarative statement</b></li>
</ul>
<p>That's what buffer pipelines do.</p>
<h2><a class="anchor" id="autotoc_md506"></a>
A Taste</h2>
<div class="fragment"><div class="line"><span class="keywordtype">void</span> compose() {</div>
<div class="line">    <span class="comment">// Create an empty audio buffer (will hold captured data)</span></div>
<div class="line">    <span class="keyword">auto</span> capture_buffer = vega.<a class="code hl_function" href="classMayaFlux_1_1Creator_a9fa2fd237baef3835e5d987262293c2c.html#a9fa2fd237baef3835e5d987262293c2c">AudioBuffer</a>()[1] | Audio;</div>
<div class="line">    <span class="comment">// Create a pipeline</span></div>
<div class="line">    <span class="keyword">auto</span> pipeline = <a class="code hl_function" href="namespaceMayaFlux_aa1955a73119c9e977f59ab989e74597e.html#aa1955a73119c9e977f59ab989e74597e">MayaFlux::create_buffer_pipeline</a>();</div>
<div class="line">    <span class="comment">// Set strategy to streaming (process as data arrives)</span></div>
<div class="line">    pipeline-&gt;with_strategy(ExecutionStrategy::STREAMING);</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// Declare the flow:</span></div>
<div class="line">    pipeline</div>
<div class="line">        &gt;&gt; BufferOperation::capture_file_from(<span class="stringliteral">&quot;path/to/audio/.wav&quot;</span>, 0)</div>
<div class="line">               .for_cycles(1) <span class="comment">// Essential for streaming</span></div>
<div class="line">        &gt;&gt; BufferOperation::route_to_buffer(capture_buffer) <span class="comment">// Route captured data to our buffer</span></div>
<div class="line">        &gt;&gt; BufferOperation::modify_buffer(capture_buffer, [](std::shared_ptr&lt;AudioBuffer&gt; buffer) {</div>
<div class="line">            <span class="keywordflow">for</span> (<span class="keyword">auto</span>&amp; sample : buffer-&gt;get_data()) {</div>
<div class="line">                sample *= <a class="code hl_function" href="namespaceMayaFlux_a8969856c48c84fe3db8145c202328672.html#a8969856c48c84fe3db8145c202328672">MayaFlux::get_uniform_random</a>(-0.5, 0.5); <span class="comment">// random &quot;texture&quot; between 0 and 0.5</span></div>
<div class="line">            }</div>
<div class="line">        });</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// Execute: runs continuously at buffer rate</span></div>
<div class="line">    pipeline-&gt;execute_buffer_rate();</div>
<div class="line">}</div>
<div class="ttc" id="aclassMayaFlux_1_1Creator_a9fa2fd237baef3835e5d987262293c2c_html_a9fa2fd237baef3835e5d987262293c2c"><div class="ttname"><a href="classMayaFlux_1_1Creator_a9fa2fd237baef3835e5d987262293c2c.html#a9fa2fd237baef3835e5d987262293c2c">MayaFlux::Creator::AudioBuffer</a></div><div class="ttdeci">auto AudioBuffer(Args &amp;&amp;... args) -&gt; CreationHandle&lt; MayaFlux::Buffers::AudioBuffer &gt;</div><div class="ttdef"><b>Definition</b> <a href="Creator_8hpp_source.html#l00210">Creator.hpp:210</a></div></div>
<div class="ttc" id="anamespaceMayaFlux_a8969856c48c84fe3db8145c202328672_html_a8969856c48c84fe3db8145c202328672"><div class="ttname"><a href="namespaceMayaFlux_a8969856c48c84fe3db8145c202328672.html#a8969856c48c84fe3db8145c202328672">MayaFlux::get_uniform_random</a></div><div class="ttdeci">double get_uniform_random(double start, double end)</div><div class="ttdoc">Generates a uniform random number.</div><div class="ttdef"><b>Definition</b> <a href="API_2Random_8cpp_source.html#l00014">API/Random.cpp:14</a></div></div>
</div><!-- fragment --><p>Run this. You'll hear the file play back at with noisy texture. But the file never played to speakers directly: it was captured, processed, accumulated, then routed.</p>
<h2><a class="anchor" id="autotoc_md507"></a>
Expansion 1: What Is a Pipeline?</h2>
<details >
<summary >
Click to expand: Declarative Processing Chains</summary>
<p></p>
<p>A <b>pipeline</b> is a declarative sequence of buffer operations that compose to form a complete computational event.</p>
<p>Unlike the previous sections where you manually:</p>
<ol type="1">
<li>Load a file</li>
<li>Get buffers</li>
<li>Create processors</li>
<li>Add to chains</li>
</ol>
<p>...a pipeline lets you describe the entire flow in one statement:</p>
<div class="fragment"><div class="line">pipeline</div>
<div class="line">    &gt;&gt; Operation1</div>
<div class="line">    &gt;&gt; Operation2</div>
<div class="line">    &gt;&gt; Operation3;</div>
</div><!-- fragment --><p>The <code>&gt;&gt;</code> operator chains operations. The pipeline executes them in order, handling all the machinery (cycles, buffer management, timing) invisibly.</p>
<p>This is why you've been learning the foundation first: <b>pipelines are just syntactic sugar over SoundFileBridge, DynamicSoundStream, SoundStreamWriter, and buffer cycles.</b></p>
<p>Understanding the previous sections makes this section obvious. You're not learning new concepts—you're composing concepts you already understand.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md508"></a>
Expansion 2: BufferOperation Types</h2>
<details >
<summary >
Click to expand: What Operations Exist</summary>
<p></p>
<p>BufferOperation is a toolkit. Common operations:</p>
<ul>
<li><b>capture_file()</b> - Read N cycles from a file, accumulate in internal stream</li>
<li><b>modify_buffer()</b> - Apply custom logic to a specific AudioBuffer</li>
<li><b>route_to_buffer()</b> - Send accumulated result to an AudioBuffer for playback</li>
<li><b>route_to_container()</b> - Send result to a DynamicSoundStream (for recording, analysis, etc.)</li>
<li><b>transform()</b> - Map/reduce on accumulated data (structural transformation)</li>
<li><b>dispatch()</b> - Execute arbitrary code with access to the data</li>
</ul>
<p>Each operation is a building block. Pipeline chains them together.</p>
<p>The full set of operations is the subject of its own tutorial. This section just shows the pattern.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md509"></a>
Expansion 3: The &lt;tt&gt;on_capture_processing&lt;/tt&gt; Pattern</h2>
<details >
<summary >
Click to expand: Processing Each Cycle</summary>
<p></p>
<p>Notice in the example:</p>
<div class="fragment"><div class="line">&gt;&gt; BufferOperation::modify([](<span class="keyword">auto</span>&amp; data, uint32_t cycle) {</div>
<div class="line">    <span class="comment">// Called every cycle as data accumulates</span></div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keyword">auto</span>&amp; sample : data) {</div>
<div class="line">        sample *= 0.5;</div>
<div class="line">    }</div>
<div class="line">})</div>
</div><!-- fragment --><p>The <code>modify</code> operation runs **each cycle**—meaning:</p>
<ul>
<li>Cycle 1: 512 samples captured, modified by your lambda</li>
<li>Cycle 2: Next 512 samples captured, modified</li>
<li>Cycle 3: And so on</li>
</ul>
<p>This is <code>on_capture_processing</code>: your custom logic runs as data arrives, not automated by external managers.</p>
<p>Automatic mode simply expects buffer manager to handle the processing of attached processors. On Demand mode expects users to provide callback timing logic.</p>
<p>For now: understand that pipelines let you hook custom logic into the capture/process/route flow.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md510"></a>
Expansion 4: Why This Matters</h2>
<details >
<summary >
Click to expand: Composability and Control</summary>
<p></p>
<p>Before pipelines, your workflow was:</p>
<ol type="1">
<li>Load file (Container)</li>
<li>Get buffers</li>
<li>Add processors to buffers</li>
<li>Play to hardware</li>
<li>Everything was real-time</li>
</ol>
<p>With pipelines, your workflow is:</p>
<ol type="1">
<li>Declare capture (file, cycle count)</li>
<li>Declare processing (what to do each cycle)</li>
<li>Declare output (where result goes)</li>
<li>Execute (all at once, deterministic, no real-time constraints)</li>
</ol>
<p>The key difference: <b>determinism</b>. You know exactly what will happen because you've declared the entire flow.</p>
<p>This is the foundation for everything beyond this tutorial:</p>
<ul>
<li>Recording sessions</li>
<li>Batch processing</li>
<li>Data analysis pipelines</li>
<li>Complex temporal arrangements</li>
<li>Multi-file composition</li>
</ul>
<p>All of it starts with this pattern: <b>declare → execute → observe</b>.</p>
<p></p>
</details>
<h2><a class="anchor" id="autotoc_md511"></a>
What Happens Next</h2>
<p>The full <b>Buffer Pipelines</b> tutorial is its own comprehensive guide. It covers:</p>
<ul>
<li>All BufferOperation types</li>
<li>Composition patterns (chaining operations)</li>
<li>Timing and cycle coordination</li>
<li>Error handling and introspection</li>
<li>Advanced patterns (branching, conditional operations, etc.)</li>
</ul>
<p>This section is just the proof-of-concept: "Here's what becomes possible when everything you've learned composes."</p>
<hr  />
<h2><a class="anchor" id="autotoc_md513"></a>
Try It (Optional)</h2>
<p>The code above will run if you have:</p>
<ul>
<li>A <code>.wav</code> file at <code>"path/to/file.wav"</code></li>
<li>All the machinery from Sections 1-3 understood</li>
</ul>
<p>If you want to experiment, use a real file path and run it.</p>
<p>But the main point is: <b>understand what's happening</b>, not just make it work.</p>
<ul>
<li>You're capturing from a file</li>
<li>Each cycle, your lambda processes 512 samples</li>
<li>Results accumulate in capture_buffer</li>
<li>Then capture_buffer plays to hardware</li>
</ul>
<p>This is real composition. Not playback. Not presets. Declarative data transformation.</p>
<h2><a class="anchor" id="autotoc_md514"></a>
The Philosophy</h2>
<p>You've now seen the complete stack:</p>
<ol type="1">
<li><b>Containers</b> hold data (load files)</li>
<li><b>Buffers</b> coordinate cycles (chunk processing)</li>
<li><b>Processors</b> transform data (effects, analysis)</li>
<li><b>Chains</b> order processors (sequence operations)</li>
<li><b>Pipelines</b> compose chains (declare complete flows)</li>
</ol>
<p>Each layer builds on the previous. None is magic. All are composable.</p>
<p>This is how <a class="el" href="namespaceMayaFlux.html" title="Main namespace for the Maya Flux audio engine.">MayaFlux</a> thinks about computation: as layered, declarative, composable building blocks.</p>
<p>Pipelines are where that thinking becomes powerful. They're not a special feature—they're just the final layer of composition.</p>
<h2><a class="anchor" id="autotoc_md515"></a>
Next: The Full Pipeline Tutorial</h2>
<p>When you're ready, the standalone **"Buffer Pipelines"** tutorial dives deep into:</p>
<ul>
<li>Every BufferOperation type with examples</li>
<li>How to compose complex workflows</li>
<li>Error handling and debugging</li>
<li>Performance considerations</li>
<li>Real-world use cases</li>
</ul>
<p>For now: you've seen the teaser. Everything you've learned so far is the foundation for that depth.</p>
<p>You understand how information flows. Pipelines just let you declare that flow elegantly. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
